{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ロジスティック回帰分析",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP7H3u2RxhvA1WfFEpOTInS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitboku/statistics-practice/blob/master/%E3%83%AD%E3%82%B8%E3%82%B9%E3%83%86%E3%82%A3%E3%83%83%E3%82%AF%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrOi2VugMeoX",
        "colab_type": "text"
      },
      "source": [
        "# ロジスティック回帰分析とは"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBkF51n9Mhz6",
        "colab_type": "text"
      },
      "source": [
        "目的変数を0から1の範囲でとりたいときに有効な分析方法。\n",
        "例えば、癌の発生確率など。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hl44YSqlT_N",
        "colab_type": "text"
      },
      "source": [
        "## 非線形回帰とは"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5m7QyB2lW-f",
        "colab_type": "text"
      },
      "source": [
        "単回帰分析と重回帰分析は線警戒機。\n",
        "非線形は直線ではない関係、例えば2上とかルートの関係。\n",
        "ロジスティック回帰分析以外には多項式回帰分析とかサポートベクトル回帰分析などがある。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kyfd1s55lq1l",
        "colab_type": "text"
      },
      "source": [
        "## 数式"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cihlru9-ltvZ",
        "colab_type": "text"
      },
      "source": [
        "ロジスティック回帰分析では以下の式を取る。\n",
        "\n",
        "$$\n",
        "p = \\frac {1} {1+ \\exp(-(a_1x_1 + \\cdots + a_nx_n + b))}\n",
        "$$\n",
        "\n",
        "これを変形すると以下のようになる。\n",
        "\n",
        "$$\n",
        "\\ln{\\frac {p} {1-p}} = a_1x_1 + \\cdots + a_nx_n + b\n",
        "$$\n",
        "\n",
        "なお、上のほうの式はシグモイド関数とも呼ばれる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5WHPqKEf7IV",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "また、上記の式をロジットと呼び、$l$で置くことがある。\n",
        "このロジットに対して指数を取ると、オッズが出てくる。\n",
        "\n",
        "$$\n",
        "\\exp(l) = \\frac {p} {1 - p}\n",
        "$$\n",
        "\n",
        "このオッズはある事象が発生する確率と発生しない確率の比になっている。\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nsb6q2bf_xU",
        "colab_type": "text"
      },
      "source": [
        "## 偏回帰係数の求め方"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU2deAI1gDhG",
        "colab_type": "text"
      },
      "source": [
        "ロジスティック回帰分析では単回帰や重回帰のように最小二乗法で求めることはできないらしい。  \n",
        "\n",
        "参考：　https://qiita.com/karaage0703/items/417934d82ac3c3c5f70e#%E3%83%AD%E3%82%B8%E3%82%B9%E3%83%86%E3%82%A3%E3%83%83%E3%82%AF%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90%E3%81%AE%E8%A7%A3%E3%81%8D%E6%96%B9\n",
        "\n",
        "\n",
        "よって、勾配降下法などを使用して逐次計算でパラメータ推定をする。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwHNOAkcraJP",
        "colab_type": "text"
      },
      "source": [
        "## 勾配降下法について"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvXJ-p1irdK7",
        "colab_type": "text"
      },
      "source": [
        "いくつかの種類がある。\n",
        "\n",
        "*   最急降下法（Gradient Descent）\n",
        "*   確率的勾配降下法（Stochastic Gradient Descent）\n",
        "*   ミニバッチ確率的勾配降下法（Minibatch SGD）\n",
        "\n",
        "計算量が少ない、オンライン学習が可能といったメリットから、たいていの場合確率的勾配降下法を使用するが、異常値に引っ張られやすい。\n",
        "\n",
        "ミニバッチ法ではまとまったデータをいくつかの組に分けて確率的勾配降下法を行う。\n",
        "全データを使用する回数のことをエポック数という。\n",
        "例えば、データ数が1000で、ミニバッチのサイズが50の時、20回学習を行うと全データを1周するので、20反復が1エポックとなる。\n",
        "\n",
        "エポック数が10なら10000のデータを使用する。ミニバッチサイズが50なので、200回学習することになる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6gTo73Frcf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}