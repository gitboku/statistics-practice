{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "サポーベクトルマシン",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN5zRtRgkq56TPo/2Gh8y5i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitboku/statistics-practice/blob/master/%E3%82%B5%E3%83%9D%E3%83%BC%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E3%83%9E%E3%82%B7%E3%83%B3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skh110fEizUD",
        "colab_type": "text"
      },
      "source": [
        "# サポートベクトルマシンとは"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVez2KtVnpnU",
        "colab_type": "text"
      },
      "source": [
        "参考：　https://logics-of-blue.com/svm-concept/\n",
        "\n",
        "外れ値のようなデータまで使うと予測精度が下がるので、本当に必要となるデータのみを使用する。\n",
        "この「本当に必要なデータ」をサポートベクトルと呼び、これを用いた機械学習がサポートベクトルマシン(Sapport vector machine: SVM)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuLsA3iIoDPS",
        "colab_type": "text"
      },
      "source": [
        "## サポートベクトルとは"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kinkdf1RoE3k",
        "colab_type": "text"
      },
      "source": [
        "「マージン最大化」という考え方によって「予測に必要なデータ」を決定する。\n",
        "マージンとは判別する境界線とデータとの距離。\n",
        "マージンが大きい場合「ほんの少しデータが変わっただけで誤判定する」ということがなくなる。\n",
        "境界線と最も近くにあるデータをサポートベクトルと呼ぶ。\n",
        "\n",
        "境界線とサポートベクトルとのマージンを大きくすることで誤判定を防ぐ。\n",
        "\n",
        "\n",
        "はっきりとクラス分けできることを前提としたマージンをハードマージンと呼ぶ。\n",
        "一方、過学習を防ぐためにあえて誤分類をある程度許すようにしたマージンをソフトマージンと呼ぶ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtosTnkreVri",
        "colab_type": "text"
      },
      "source": [
        "## ハードマージン\n",
        "\n",
        "参考： https://kenyu-life.com/2019/02/11/support_vector_machine/\n",
        "\n",
        "境界線の式を以下のように定義する。\n",
        "$w$は重み(n次元ベクトル)で、bはバイアス(スカラー)。\n",
        "$$\n",
        "w^Tx + b = 0\n",
        "$$\n",
        "\n",
        "ここで、$w^Tx + b > 0$となるxの集合を$K_1$とし、$w^Tx + b < 0$となるxの集合を$K_2$とする。\n",
        "\n",
        "さらに、$K_2$のラベルを-1ということにして、ラベルのベクトルを$t$で表せば、以下のように定義できる。\n",
        "\n",
        "$$\n",
        "t_i(w^Tx_i + b) > 0\\ (i = 1,2,\\cdots,n)\n",
        "$$\n",
        "\n",
        "### 境界線とのマージン\n",
        "\n",
        "2次元でのマージンは点と直線の距離の公式をそのまま使える。\n",
        "\n",
        "$$\n",
        "d = \\frac {|w_1x_1 + w_2x_2 + b|}{\\sqrt{w^2_1 + w^2_2}}\n",
        "$$\n",
        "\n",
        "これをn次元用に一般化すると以下のようになる(w, xはn次元ベクトル)。\n",
        "\n",
        "$$\n",
        "d = \\frac {|w^Tx + b|}{||w||}\n",
        "$$\n",
        "\n",
        "ラベルを使用した式に入れ替えると以下のようになる。\n",
        "\n",
        "$$\n",
        "\\frac {t_i(w^Tx_i + b)}{||w||} \\ge M\n",
        "$$\n",
        "\n",
        "「この式がすべてのクラスのサポートベクトルに対してマージン最大化する」と「すべてのベクトルが祖のマージンよりも距離が長い」という二つの条件を満たすことで、最適化する。\n",
        "\n",
        "ここで、両辺をMで割る。\n",
        "\n",
        "$$\n",
        "\\frac {t_i(w^Tx_i + b)}{M||w||} \\ge 1\n",
        "$$\n",
        "\n",
        "さらに、以下のように入れ替える。\n",
        "\n",
        "$$\n",
        "\\begin{eqnarray}\n",
        "\\tilde{w} &=& \\frac {w}{M||w||}\\\\\n",
        "\\tilde{b} &=& \\frac {b}{M||w||}\n",
        "\\end{eqnarray}\n",
        "$$\n",
        "\n",
        "最終的に以下のようになる。\n",
        "$$\n",
        "t_i(\\tilde{w}^Tx_i + \\tilde{b}) = 1\n",
        "$$\n",
        "\n",
        "サポートベクトルに対しては以下の統合が成立するので、これを目的関数とする。\n",
        "\n",
        "$$\n",
        "\\tilde{M} = \\frac {t_i(\\tilde{w}^Tx_i + \\tilde{b})}{||\\tilde{w}||} = \\frac {1}{||\\tilde{w}||}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogr32NaLTTPd",
        "colab_type": "text"
      },
      "source": [
        "この「マージンを最大化する」という目標は「マージンの逆数を最小化する」というように書き換えられる。\n",
        "よって、以下のように変換する。\n",
        "二乗や2で割っているのは計算の簡単のため。\n",
        "\n",
        "$$\n",
        "\\min_{w,b}{\\frac {1}{2}} ||w||^2,\\ t_i(w^Tx_i + b) \\ge 1\\ (i=1,2,\\cdots,n)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjNz55VleLkU",
        "colab_type": "text"
      },
      "source": [
        "## ソフトマージン\n",
        "\n",
        "ソフトマージンはハードマージンよりも懸命なSVM。\n",
        "線形分離不可能なデータだと、マージン内部にサポーベクトル以外のデータが入り込んでいる。\n",
        "\n",
        "そこで、ハードマージンの式にスラッグ変数$\\xi$を導入して制約を弱める。\n",
        "\n",
        "$$\n",
        "t_i(w^Tx_i + b) \\ge 1 - \\xi\\\\\n",
        "\\xi_i = max{0, M - \\frac {t_i(w^Tx_i + b)}{||w||}}\n",
        "$$\n",
        "\n",
        "例えば、マージンMが1の時、直線からの距離0.4の位置に別のデータが入り込んでいたとする。\n",
        "この場合、以下のように制約が小さくなる。\n",
        "\n",
        "$$\n",
        "\\begin{eqnarray}\n",
        "\\xi_i &=& \\max\\{0, M - \\frac {t_i(w^Tx_i + b)}{||w||}\\}\\\\\n",
        "\\xi_i &=& \\max\\{0, (1-0.4)\\}\\\\\n",
        "\\xi_i &=& 0.6\n",
        "\\end{eqnarray}\n",
        "$$\n",
        "\n",
        "ソフトマージンの目的関数は以下のようになる。\n",
        "\n",
        "$$\n",
        "\\min\\{\\frac{1}{2}||w^T||^2 + C\\sum_{i=1}^n\\xi_i\\}\n",
        "$$\n",
        "\n",
        "制約条件は以下の通りである。\n",
        "\n",
        "$$\n",
        "t_i(w^Tx_i + b) \\ge 1 - \\xi_i, \\xi_i \\ge 0\\ (i=1,2,\\cdots,n)\n",
        "$$\n",
        "\n",
        "ここで、Cは正規化係数であり、ペナルティの度合いでもある。\n",
        "この値が大きくなるほど$\\xi$を抑制する力が強くなり、$\\xi = \\infty$ではハードマージンと同じになる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58QMy0-7itWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}